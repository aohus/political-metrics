import json
import re
from collections import Counter, defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Optional, Set, Tuple

import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.feature_extraction.text import TfidfVectorizer
from wordcloud import WordCloud

# Korean NLP (ì‹¤ì œ ì‚¬ìš©ì‹œ konlpy ì„¤ì¹˜ í•„ìš”)
try:
    from konlpy.tag import Komoran, Okt

    KONLPY_AVAILABLE = True
except ImportError:
    KONLPY_AVAILABLE = False
    print("KoNLPyê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")


class PoliticalIdeology(Enum):
    """ì •ì¹˜ ì´ë… ë¶„ë¥˜"""

    VERY_PROGRESSIVE = "ë§¤ìš° ì§„ë³´"
    PROGRESSIVE = "ì§„ë³´"
    MODERATE = "ì¤‘ë„"
    CONSERVATIVE = "ë³´ìˆ˜"
    VERY_CONSERVATIVE = "ë§¤ìš° ë³´ìˆ˜"
    UNKNOWN = "ë¶„ì„ë¶ˆê°€"


class PolicyArea(Enum):
    """ì •ì±… ë¶„ì•¼"""

    ECONOMY = "ê²½ì œ/ê¸ˆìœµ"
    WELFARE = "ë³µì§€/ì‚¬íšŒë³´ì¥"
    EDUCATION = "êµìœ¡/ê³¼í•™ê¸°ìˆ "
    ENVIRONMENT = "í™˜ê²½/ì—ë„ˆì§€"
    SECURITY = "êµ­ë°©/ì•ˆë³´"
    FOREIGN_AFFAIRS = "ì™¸êµ/í†µì¼"
    JUSTICE = "ì‚¬ë²•/ë²•ë¬´"
    ADMINISTRATION = "í–‰ì •/ì§€ë°©ìì¹˜"
    CULTURE = "ë¬¸í™”/ì²´ìœ¡"
    HEALTH = "ë³´ê±´/ì˜ë£Œ"
    AGRICULTURE = "ë†ë¦¼/ìˆ˜ì‚°"
    LABOR = "ë…¸ë™/ê³ ìš©"
    TRANSPORTATION = "êµí†µ/ê±´ì„¤"
    COMMUNICATION = "ë°©ì†¡/í†µì‹ "
    WOMEN_FAMILY = "ì—¬ì„±/ê°€ì¡±"
    OTHER = "ê¸°íƒ€"


@dataclass
class SpecializationScore:
    """ì „ë¬¸ì„± ì ìˆ˜"""

    area: PolicyArea
    bills_count: int = 0
    speeches_count: int = 0
    committee_activity: float = 0.0
    consistency_score: float = 0.0  # ì¼ê´€ì„± ì ìˆ˜
    depth_score: float = 0.0  # ê¹Šì´ ì ìˆ˜
    total_score: float = 0.0


@dataclass
class IdeologyIndicator:
    """ì´ë… ì§€í‘œ"""

    keyword_score: float = 0.0  # í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜
    voting_score: float = 0.0  # í‘œê²° íŒ¨í„´ ì ìˆ˜
    bill_score: float = 0.0  # ë²•ì•ˆ ì„±í–¥ ì ìˆ˜
    alliance_score: float = 0.0  # ì •ì¹˜ì  ì—°ëŒ€ ì ìˆ˜
    overall_score: float = 0.0  # ì¢…í•© ì ìˆ˜


@dataclass
class PoliticalProfile:
    """ì •ì¹˜ì  í”„ë¡œí•„"""

    member_name: str
    specializations: List[SpecializationScore] = field(default_factory=list)
    main_interests: List[Tuple[str, float]] = field(
        default_factory=list
    )  # (ì£¼ì œ, ê´€ì‹¬ë„)
    ideology: PoliticalIdeology = PoliticalIdeology.UNKNOWN
    ideology_scores: IdeologyIndicator = field(default_factory=IdeologyIndicator)
    activity_timeline: Dict[str, Dict] = field(default_factory=dict)
    keyword_trends: Dict[str, List[float]] = field(default_factory=dict)


class PoliticalKeywords:
    """ì •ì¹˜ ì´ë…ë³„ í‚¤ì›Œë“œ ì‚¬ì „"""

    def __init__(self):
        self.progressive_keywords = [
            # ê²½ì œ ì§„ë³´ í‚¤ì›Œë“œ
            "ì†Œë“ë¶ˆí‰ë“±",
            "ìµœì €ì„ê¸ˆ",
            "ë¶€ì˜ì„¸",
            "ëŒ€ê¸°ì—…ê·œì œ",
            "ì¬ë²Œê°œí˜",
            "ë…¸ë™ê¶Œ",
            "ì‚¬íšŒì ê²½ì œ",
            "ê³µì •ê±°ë˜",
            "ì„œë¯¼ê²½ì œ",
            "ì²­ë…„ì¼ìë¦¬",
            # ì‚¬íšŒ ì§„ë³´ í‚¤ì›Œë“œ
            "ì¸ê¶Œ",
            "ì„±í‰ë“±",
            "ë‹¤ë¬¸í™”",
            "ì†Œìˆ˜ì",
            "ì°¨ë³„ê¸ˆì§€",
            "ì„±ì†Œìˆ˜ì",
            "ì—¬ì„±ê¶Œìµ",
            "ì¥ì• ì¸ê¶Œ",
            "ì‹œë¯¼ê¶Œ",
            "í‘œí˜„ì˜ììœ ",
            # ë³µì§€ ì§„ë³´ í‚¤ì›Œë“œ
            "ë³´í¸ë³µì§€",
            "ë¬´ìƒêµìœ¡",
            "ë¬´ìƒì˜ë£Œ",
            "ê¸°ë³¸ì†Œë“",
            "ë³µì§€í™•ëŒ€",
            "ì‚¬íšŒë³´ì¥",
            "ê³µê³µì„œë¹„ìŠ¤",
            "ë³µì§€êµ­ê°€",
            # í™˜ê²½/í‰í™” í‚¤ì›Œë“œ
            "íƒˆí•µ",
            "ì¬ìƒì—ë„ˆì§€",
            "ê¸°í›„ë³€í™”",
            "í™˜ê²½ë³´í˜¸",
            "í‰í™”í†µì¼",
            "êµ°ì¶•",
            "í•µë¬´ê¸°ë°˜ëŒ€",
            "ë°˜ì „í‰í™”",
        ]

        self.conservative_keywords = [
            # ê²½ì œ ë³´ìˆ˜ í‚¤ì›Œë“œ
            "ììœ ì‹œì¥",
            "ê·œì œì™„í™”",
            "ë¯¼ì˜í™”",
            "ê¸°ì—…í™œë™",
            "íˆ¬ìí™œì„±í™”",
            "ì„¸ê¸ˆê°ë©´",
            "ê²½ì œì„±ì¥",
            "ì‹œì¥ê²½ì œ",
            "ê²½ìŸë ¥ê°•í™”",
            # ì‚¬íšŒ ë³´ìˆ˜ í‚¤ì›Œë“œ
            "ì „í†µê°€ì¹˜",
            "ê°€ì¡±ì œë„",
            "êµ­ê°€ì •ì²´ì„±",
            "ì• êµ­",
            "ì „í†µë¬¸í™”",
            "ë„ë•ì„±",
            "ì§ˆì„œ",
            "ì•ˆì •",
            # ì•ˆë³´ ë³´ìˆ˜ í‚¤ì›Œë“œ
            "êµ­ê°€ì•ˆë³´",
            "êµ­ë°©ë ¥",
            "í•œë¯¸ë™ë§¹",
            "ë¶í•œìœ„í˜‘",
            "ì•ˆë³´ìš°ì„ ",
            "êµ­ë°©ì˜ˆì‚°",
            "êµ°ì‚¬ë ¥",
            "ëŒ€ë¶ì œì¬",
            # ë²•ì§ˆì„œ í‚¤ì›Œë“œ
            "ë²•ì§ˆì„œ",
            "ì²˜ë²Œê°•í™”",
            "ë²”ì£„ì˜ˆë°©",
            "ì‚¬íšŒì•ˆì „",
            "ì—„ë²Œì£¼ì˜",
        ]

        self.policy_keywords = {
            PolicyArea.ECONOMY: [
                "ê²½ì œ",
                "ê¸ˆìœµ",
                "íˆ¬ì",
                "ê¸°ì—…",
                "ì‚°ì—…",
                "ë¬´ì—­",
                "ìˆ˜ì¶œ",
                "GDP",
                "ì„±ì¥",
                "ê³ ìš©",
                "ì¼ìë¦¬",
                "ì°½ì—…",
                "ë²¤ì²˜",
                "ìŠ¤íƒ€íŠ¸ì—…",
                "í˜ì‹ ",
            ],
            PolicyArea.WELFARE: [
                "ë³µì§€",
                "ì—°ê¸ˆ",
                "ì˜ë£Œë³´í—˜",
                "ê¸°ì´ˆìƒí™œ",
                "ì‚¬íšŒë³´ì¥",
                "ëŒë´„",
                "ì•„ë™",
                "ë…¸ì¸",
                "ì¥ì• ì¸",
                "ì €ì†Œë“ì¸µ",
                "ì·¨ì•½ê³„ì¸µ",
            ],
            PolicyArea.EDUCATION: [
                "êµìœ¡",
                "ëŒ€í•™",
                "ì…ì‹œ",
                "í•™ìƒ",
                "êµì‚¬",
                "ê³¼í•™ê¸°ìˆ ",
                "ì—°êµ¬ê°œë°œ",
                "R&D",
                "ICT",
                "AI",
                "ë””ì§€í„¸",
                "í˜ì‹ ",
            ],
            PolicyArea.ENVIRONMENT: [
                "í™˜ê²½",
                "ê¸°í›„",
                "ì—ë„ˆì§€",
                "íƒ„ì†Œ",
                "ì¹œí™˜ê²½",
                "ì¬ìƒì—ë„ˆì§€",
                "ì›ì „",
                "ëŒ€ê¸°",
                "ìˆ˜ì§ˆ",
                "íê¸°ë¬¼",
                "ë…¹ìƒ‰",
                "ì§€ì†ê°€ëŠ¥",
            ],
            PolicyArea.SECURITY: [
                "êµ­ë°©",
                "ì•ˆë³´",
                "êµ°ì‚¬",
                "ë¶í•œ",
                "í†µì¼",
                "í•œë¯¸ë™ë§¹",
                "í‰í™”",
                "êµ°ì¸",
                "ë³‘ì—­",
                "êµ­ê°€ì•ˆì „",
            ],
            PolicyArea.JUSTICE: [
                "ë²•ë¥ ",
                "ì‚¬ë²•",
                "ê²€ì°°",
                "ë²•ì›",
                "ì¬íŒ",
                "ë²•ì œ",
                "ê°œì •",
                "í—Œë²•",
                "í˜•ë²•",
                "ë¯¼ë²•",
                "ì ˆì°¨",
            ],
        }


class TextAnalyzer:
    """í…ìŠ¤íŠ¸ ë¶„ì„ê¸°"""

    def __init__(self):
        self.keywords_db = PoliticalKeywords()
        if KONLPY_AVAILABLE:
            self.tokenizer = Okt()
        else:
            self.tokenizer = None

    def extract_keywords(self, text: str, top_k: int = 20) -> List[Tuple[str, int]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text:
            return []

        # ê¸°ë³¸ ì „ì²˜ë¦¬
        text = self._preprocess_text(text)

        if self.tokenizer:
            # KoNLPy ì‚¬ìš©
            tokens = self.tokenizer.nouns(text)
            tokens = [token for token in tokens if len(token) > 1]
        else:
            # ê¸°ë³¸ í† í°í™” (ê³µë°± ê¸°ì¤€)
            tokens = text.split()
            tokens = [token for token in tokens if len(token) > 1]

        # í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°
        keyword_freq = Counter(tokens)
        return keyword_freq.most_common(top_k)

    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r"<[^>]+>", "", text)

        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ìœ ì§€)
        text = re.sub(r"[^\w\sê°€-í£]", " ", text)

        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r"\s+", " ", text)

        return text.strip()

    def calculate_ideology_score(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì´ë… ì ìˆ˜ ê³„ì‚° (-1: ì§„ë³´, 0: ì¤‘ë„, +1: ë³´ìˆ˜)"""
        if not text:
            return 0.0

        text_lower = text.lower()

        progressive_count = sum(
            1
            for keyword in self.keywords_db.progressive_keywords
            if keyword in text_lower
        )
        conservative_count = sum(
            1
            for keyword in self.keywords_db.conservative_keywords
            if keyword in text_lower
        )

        total_keywords = progressive_count + conservative_count
        if total_keywords == 0:
            return 0.0

        # -1 ~ +1 ë²”ìœ„ë¡œ ì •ê·œí™”
        score = (conservative_count - progressive_count) / total_keywords
        return score

    def classify_policy_area(self, text: str) -> Dict[PolicyArea, float]:
        """í…ìŠ¤íŠ¸ì˜ ì •ì±… ë¶„ì•¼ ë¶„ë¥˜"""
        text_lower = text.lower()
        area_scores = {}

        for area, keywords in self.keywords_db.policy_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            area_scores[area] = score

        # ì •ê·œí™”
        total_score = sum(area_scores.values())
        if total_score > 0:
            area_scores = {
                area: score / total_score for area, score in area_scores.items()
            }

        return area_scores


class SpecializationAnalyzer:
    """ì „ë¬¸ì„± ë¶„ì„ê¸°"""

    def __init__(self, text_analyzer: TextAnalyzer):
        self.text_analyzer = text_analyzer

    def analyze_bill_specialization(
        self, bills: List[Dict]
    ) -> Dict[PolicyArea, SpecializationScore]:
        """ë²•ì•ˆ ê¸°ë°˜ ì „ë¬¸ì„± ë¶„ì„"""
        area_analysis = defaultdict(lambda: SpecializationScore(area=PolicyArea.OTHER))

        # ìœ„ì›íšŒë³„ ë¶„ì•¼ ë§¤í•‘
        committee_mapping = {
            "ê¸°íšì¬ì •": PolicyArea.ECONOMY,
            "êµìœ¡": PolicyArea.EDUCATION,
            "ê³¼í•™ê¸°ìˆ ì •ë³´ë°©ì†¡í†µì‹ ": PolicyArea.COMMUNICATION,
            "ì™¸êµí†µì¼": PolicyArea.FOREIGN_AFFAIRS,
            "êµ­ë°©": PolicyArea.SECURITY,
            "í–‰ì •ì•ˆì „": PolicyArea.ADMINISTRATION,
            "ë¬¸í™”ì²´ìœ¡ê´€ê´‘": PolicyArea.CULTURE,
            "ë†ë¦¼ì¶•ì‚°ì‹í’ˆí•´ì–‘ìˆ˜ì‚°": PolicyArea.AGRICULTURE,
            "ì‚°ì—…í†µìƒìì›": PolicyArea.ECONOMY,
            "ë³´ê±´ë³µì§€": PolicyArea.WELFARE,
            "í™˜ê²½ë…¸ë™": PolicyArea.ENVIRONMENT,
            "ë²•ì œì‚¬ë²•": PolicyArea.JUSTICE,
            "ì •ë¬´": PolicyArea.ADMINISTRATION,
            "ì—¬ì„±ê°€ì¡±": PolicyArea.WOMEN_FAMILY,
            "êµ­í† êµí†µ": PolicyArea.TRANSPORTATION,
        }

        for bill in bills:
            # ìœ„ì›íšŒ ê¸°ë°˜ ë¶„ì•¼ ë¶„ë¥˜
            committee = bill.get("JRCMIT_NM", "")
            area = PolicyArea.OTHER

            for comm_key, mapped_area in committee_mapping.items():
                if comm_key in committee:
                    area = mapped_area
                    break

            # ë²•ì•ˆ ì œëª© ê¸°ë°˜ ì¶”ê°€ ë¶„ì„
            bill_title = bill.get("BILL_NM", "") + " " + bill.get("BILL_SUMMARY", "")
            area_scores = self.text_analyzer.classify_policy_area(bill_title)

            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë¶„ì•¼ ì„ íƒ
            if area_scores:
                max_area = max(area_scores.items(), key=lambda x: x[1])
                if max_area[1] > 0.1:  # ì„ê³„ê°’ ì´ìƒ
                    area = max_area[0]

            # ì ìˆ˜ ì—…ë°ì´íŠ¸
            spec_score = area_analysis[area]
            spec_score.area = area
            spec_score.bills_count += 1

            # ë²•ì•ˆ í†µê³¼ ì—¬ë¶€ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
            if bill.get("RGS_CONF_RSLT") == "ê°€ê²°":
                spec_score.depth_score += 2.0
            elif bill.get("RGS_CONF_RSLT") == "ê³„ë¥˜":
                spec_score.depth_score += 1.0
            else:
                spec_score.depth_score += 0.5

        # ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚° (ì‹œê°„ë³„ í™œë™ ë¶„í¬)
        for area, score in area_analysis.items():
            if score.bills_count > 0:
                # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°
                score.total_score = score.bills_count * 0.4 + score.depth_score * 0.6

                # ì¼ê´€ì„± ì ìˆ˜ (ë²•ì•ˆ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë†’ìŒ)
                score.consistency_score = min(score.bills_count / 10.0, 1.0)

        return dict(area_analysis)

    def analyze_speech_specialization(
        self, speeches: List[Dict]
    ) -> Dict[PolicyArea, float]:
        """ë°œì–¸ ê¸°ë°˜ ì „ë¬¸ì„± ë¶„ì„"""
        area_speech_counts = defaultdict(int)

        for speech in speeches:
            content = speech.get("SPEAK_CONT", "")
            if not content:
                continue

            area_scores = self.text_analyzer.classify_policy_area(content)

            # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¶„ì•¼ì— ì ìˆ˜ ë¶€ì—¬
            if area_scores:
                max_area = max(area_scores.items(), key=lambda x: x[1])
                if max_area[1] > 0.1:
                    area_speech_counts[max_area[0]] += 1

        # ì •ê·œí™”
        total_speeches = sum(area_speech_counts.values())
        if total_speeches > 0:
            return {
                area: count / total_speeches
                for area, count in area_speech_counts.items()
            }

        return {}

    def calculate_expertise_ranking(
        self,
        bill_analysis: Dict[PolicyArea, SpecializationScore],
        speech_analysis: Dict[PolicyArea, float],
    ) -> List[SpecializationScore]:
        """ì „ë¬¸ì„± ìˆœìœ„ ê³„ì‚°"""
        # ë²•ì•ˆê³¼ ë°œì–¸ ë¶„ì„ ê²°í•©
        for area, bill_score in bill_analysis.items():
            speech_score = speech_analysis.get(area, 0.0)

            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            bill_score.speeches_count = int(speech_score * 100)  # ìƒëŒ€ì  ë°œì–¸ íšŸìˆ˜
            bill_score.total_score = (
                bill_score.total_score * 0.7 + speech_score * 30 * 0.3
            )  # ë²•ì•ˆ 70%, ë°œì–¸ 30%

        # ì ìˆ˜ìˆœ ì •ë ¬
        ranked_scores = sorted(
            bill_analysis.values(), key=lambda x: x.total_score, reverse=True
        )

        return ranked_scores[:5]  # ìƒìœ„ 5ê°œ ë¶„ì•¼


class IdeologyAnalyzer:
    """ì •ì¹˜ ì´ë… ë¶„ì„ê¸°"""

    def __init__(self, text_analyzer: TextAnalyzer):
        self.text_analyzer = text_analyzer

    def analyze_bill_ideology(self, bills: List[Dict]) -> float:
        """ë²•ì•ˆ ê¸°ë°˜ ì´ë… ë¶„ì„"""
        ideology_scores = []

        for bill in bills:
            bill_text = bill.get("BILL_NM", "") + " " + bill.get("BILL_SUMMARY", "")
            score = self.text_analyzer.calculate_ideology_score(bill_text)

            # ë²•ì•ˆ í†µê³¼ ì—¬ë¶€ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
            weight = 1.0
            if bill.get("RGS_CONF_RSLT") == "ê°€ê²°":
                weight = 2.0  # í†µê³¼ëœ ë²•ì•ˆì— ë” ë†’ì€ ê°€ì¤‘ì¹˜

            ideology_scores.extend([score] * int(weight))

        return np.mean(ideology_scores) if ideology_scores else 0.0

    def analyze_speech_ideology(self, speeches: List[Dict]) -> float:
        """ë°œì–¸ ê¸°ë°˜ ì´ë… ë¶„ì„"""
        ideology_scores = []

        for speech in speeches:
            content = speech.get("SPEAK_CONT", "")
            if content:
                score = self.text_analyzer.calculate_ideology_score(content)
                ideology_scores.append(score)

        return np.mean(ideology_scores) if ideology_scores else 0.0

    def analyze_voting_ideology(
        self, voting_records: List[Dict], party_positions: Dict[str, float] = None
    ) -> float:
        """í‘œê²° ê¸°ë°˜ ì´ë… ë¶„ì„"""
        if not party_positions:
            # ê¸°ë³¸ ì •ë‹¹ë³„ ì´ë… ì ìˆ˜ (-1: ì§„ë³´, +1: ë³´ìˆ˜)
            party_positions = {
                "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹": -0.3,
                "êµ­ë¯¼ì˜í˜": 0.4,
                "ì •ì˜ë‹¹": -0.8,
                "êµ­ë¯¼ì˜ë‹¹": 0.1,
                "ê¸°ë³¸ì†Œë“ë‹¹": -0.9,
                "ì‹œëŒ€ì „í™˜": -0.4,
            }

        ideology_scores = []

        for vote in voting_records:
            vote_result = vote.get("VOTE_RSLT", "")
            bill_id = vote.get("BILL_ID", "")

            # ë²•ì•ˆë³„ ì •ë‹¹ í‘œê²° íŒ¨í„´ ë¶„ì„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
            # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ëœ ë²„ì „
            if vote_result in ["ì°¬ì„±", "ë°˜ëŒ€"]:
                # ì†Œì† ì •ë‹¹ì˜ ê¸°ë³¸ ì´ë… ì ìˆ˜ ì‚¬ìš©
                member_party = vote.get("PARTY_NM", "")
                if member_party in party_positions:
                    ideology_scores.append(party_positions[member_party])

        return np.mean(ideology_scores) if ideology_scores else 0.0

    def classify_ideology(
        self, ideology_indicator: IdeologyIndicator
    ) -> PoliticalIdeology:
        """ì¢…í•© ì´ë… ë¶„ë¥˜"""
        overall_score = ideology_indicator.overall_score

        if overall_score < -0.6:
            return PoliticalIdeology.VERY_PROGRESSIVE
        elif overall_score < -0.2:
            return PoliticalIdeology.PROGRESSIVE
        elif overall_score < 0.2:
            return PoliticalIdeology.MODERATE
        elif overall_score < 0.6:
            return PoliticalIdeology.CONSERVATIVE
        else:
            return PoliticalIdeology.VERY_CONSERVATIVE


class InterestAnalyzer:
    """ê´€ì‹¬ ë¶„ì•¼ ë¶„ì„ê¸°"""

    def __init__(self, text_analyzer: TextAnalyzer):
        self.text_analyzer = text_analyzer

    def analyze_temporal_interests(
        self, activities: List[Dict], time_windows: int = 6
    ) -> Dict[str, List[float]]:
        """ì‹œê°„ë³„ ê´€ì‹¬ ë³€í™” ë¶„ì„"""
        # í™œë™ì„ ì‹œê°„ìˆœ ì •ë ¬
        sorted_activities = sorted(
            activities, key=lambda x: x.get("date", "2000-01-01")
        )

        if not sorted_activities:
            return {}

        # ì‹œê°„ êµ¬ê°„ ë‚˜ëˆ„ê¸°
        start_date = datetime.strptime(
            sorted_activities[0].get("date", "2020-01-01"), "%Y-%m-%d"
        )
        end_date = datetime.strptime(
            sorted_activities[-1].get("date", "2024-01-01"), "%Y-%m-%d"
        )

        time_interval = (end_date - start_date) / time_windows
        keyword_timeline = defaultdict(lambda: [0] * time_windows)

        for activity in sorted_activities:
            activity_date = datetime.strptime(
                activity.get("date", "2020-01-01"), "%Y-%m-%d"
            )
            time_index = min(
                int((activity_date - start_date) / time_interval), time_windows - 1
            )

            # í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            text = activity.get("title", "") + " " + activity.get("content", "")
            keywords = self.text_analyzer.extract_keywords(text, top_k=10)

            for keyword, count in keywords:
                keyword_timeline[keyword][time_index] += count

        return dict(keyword_timeline)

    def identify_core_interests(
        self, all_activities: List[Dict], min_frequency: int = 3
    ) -> List[Tuple[str, float]]:
        """í•µì‹¬ ê´€ì‹¬ì‚¬ ì‹ë³„"""
        all_text = ""
        for activity in all_activities:
            text = activity.get("title", "") + " " + activity.get("content", "")
            all_text += text + " "

        # ì „ì²´ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.text_analyzer.extract_keywords(all_text, top_k=50)

        # ìµœì†Œ ë¹ˆë„ ì´ìƒì¸ í‚¤ì›Œë“œë§Œ ì„ íƒ
        core_interests = [
            (keyword, freq) for keyword, freq in keywords if freq >= min_frequency
        ]

        # ê´€ì‹¬ë„ ì ìˆ˜ ê³„ì‚° (ë¹ˆë„ + ì§€ì†ì„±)
        total_freq = sum(freq for _, freq in core_interests)
        normalized_interests = [
            (keyword, freq / total_freq) for keyword, freq in core_interests
        ]

        return normalized_interests[:20]  # ìƒìœ„ 20ê°œ


class PoliticalProfiler:
    """í†µí•© ì •ì¹˜ í”„ë¡œí•„ ë¶„ì„ê¸°"""

    def __init__(self, api_client):
        self.api_client = api_client
        self.text_analyzer = TextAnalyzer()
        self.specialization_analyzer = SpecializationAnalyzer(self.text_analyzer)
        self.ideology_analyzer = IdeologyAnalyzer(self.text_analyzer)
        self.interest_analyzer = InterestAnalyzer(self.text_analyzer)

    def create_comprehensive_profile(self, member_name: str) -> PoliticalProfile:
        """ì¢…í•© ì •ì¹˜ í”„ë¡œí•„ ìƒì„±"""
        print(f"ì˜ì› '{member_name}' ì •ì¹˜ í”„ë¡œí•„ ë¶„ì„ ì¤‘...")

        # ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘
        bills = self.api_client.get_bills_by_member(member_name)
        speeches = self.api_client.get_plenary_minutes(member_name)
        speeches.extend(self.api_client.get_committee_minutes(member_name))
        voting_records = self.api_client.get_voting_records(member_name)

        # í™œë™ ë°ì´í„° í†µí•©
        all_activities = []

        # ë²•ì•ˆ ë°ì´í„° ë³€í™˜
        for bill in bills:
            all_activities.append(
                {
                    "type": "bill",
                    "date": bill.get("PPSL_DT", "2020-01-01"),
                    "title": bill.get("BILL_NM", ""),
                    "content": bill.get("BILL_SUMMARY", ""),
                }
            )

        # ë°œì–¸ ë°ì´í„° ë³€í™˜
        for speech in speeches:
            all_activities.append(
                {
                    "type": "speech",
                    "date": speech.get("MTGDT", "2020-01-01"),
                    "title": f"íšŒì˜ ë°œì–¸",
                    "content": speech.get("SPEAK_CONT", ""),
                }
            )

        # 1. ì „ë¬¸ì„± ë¶„ì„
        bill_specialization = self.specialization_analyzer.analyze_bill_specialization(
            bills
        )
        speech_specialization = (
            self.specialization_analyzer.analyze_speech_specialization(speeches)
        )
        specializations = self.specialization_analyzer.calculate_expertise_ranking(
            bill_specialization, speech_specialization
        )

        # 2. ì´ë… ë¶„ì„
        bill_ideology = self.ideology_analyzer.analyze_bill_ideology(bills)
        speech_ideology = self.ideology_analyzer.analyze_speech_ideology(speeches)
        voting_ideology = self.ideology_analyzer.analyze_voting_ideology(voting_records)

        ideology_indicator = IdeologyIndicator(
            bill_score=bill_ideology,
            keyword_score=speech_ideology,
            voting_score=voting_ideology,
            overall_score=(
                bill_ideology * 0.4 + speech_ideology * 0.3 + voting_ideology * 0.3
            ),
        )

        ideology = self.ideology_analyzer.classify_ideology(ideology_indicator)

        # 3. ê´€ì‹¬ì‚¬ ë¶„ì„
        core_interests = self.interest_analyzer.identify_core_interests(all_activities)
        interest_timeline = self.interest_analyzer.analyze_temporal_interests(
            all_activities
        )

        # 4. ì‹œê°„ë³„ í™œë™ íŒ¨í„´
        activity_timeline = self._create_activity_timeline(all_activities)

        return PoliticalProfile(
            member_name=member_name,
            specializations=specializations,
            main_interests=core_interests,
            ideology=ideology,
            ideology_scores=ideology_indicator,
            activity_timeline=activity_timeline,
            keyword_trends=interest_timeline,
        )

    def _create_activity_timeline(self, activities: List[Dict]) -> Dict[str, Dict]:
        """í™œë™ íƒ€ì„ë¼ì¸ ìƒì„±"""
        timeline = defaultdict(lambda: {"bills": 0, "speeches": 0, "total": 0})

        for activity in activities:
            date_str = activity.get("date", "2020-01-01")
            year_month = date_str[:7]  # YYYY-MM í˜•íƒœ

            activity_type = activity.get("type", "other")
            timeline[year_month][activity_type] += 1
            timeline[year_month]["total"] += 1

        return dict(timeline)


class ProfileReporter:
    """í”„ë¡œí•„ ë³´ê³ ì„œ ìƒì„±ê¸°"""

    @staticmethod
    def generate_comprehensive_report(profile: PoliticalProfile) -> str:
        """ì¢…í•© í”„ë¡œí•„ ë³´ê³ ì„œ ìƒì„±"""
        report = f"""
{'='*80}
êµ­íšŒì˜ì› ì •ì¹˜ì  í”„ë¡œí•„ ë¶„ì„ ë³´ê³ ì„œ
{'='*80}

ğŸ‘¤ ì˜ì›ëª…: {profile.member_name}

ğŸ¯ ì •ì¹˜ ì´ë… ë¶„ì„
- ì¢…í•© ì´ë…: {profile.ideology.value}
- ì´ë… ì ìˆ˜: {profile.ideology_scores.overall_score:.3f} 
  (ì§„ë³´ â† -1.0 ï½ 0 ï½ +1.0 â†’ ë³´ìˆ˜)

ğŸ“Š ì„¸ë¶€ ì´ë… ì§€í‘œ:
- ë²•ì•ˆ ê¸°ë°˜ ì ìˆ˜: {profile.ideology_scores.bill_score:.3f}
- ë°œì–¸ ê¸°ë°˜ ì ìˆ˜: {profile.ideology_scores.keyword_score:.3f}  
- í‘œê²° ê¸°ë°˜ ì ìˆ˜: {profile.ideology_scores.voting_score:.3f}

ğŸ† ì „ë¬¸ ë¶„ì•¼ (ìƒìœ„ 5ê°œ)
"""

        for i, spec in enumerate(profile.specializations[:5], 1):
            report += f"""
{i}. {spec.area.value}
   - ê´€ë ¨ ë²•ì•ˆ: {spec.bills_count}ê±´
   - ì „ë¬¸ì„± ì ìˆ˜: {spec.total_score:.1f}ì 
   - ì¼ê´€ì„±: {spec.consistency_score:.1f}ì 
   - ê¹Šì´: {spec.depth_score:.1f}ì 
"""

        report += "\nğŸ’¡ í•µì‹¬ ê´€ì‹¬ì‚¬ (ìƒìœ„ 10ê°œ)\n"
        for i, (interest, score) in enumerate(profile.main_interests[:10], 1):
            report += f"{i:2d}. {interest} ({score:.1%})\n"

        # í™œë™ íŒ¨í„´ ìš”ì•½
        if profile.activity_timeline:
            recent_months = sorted(profile.activity_timeline.keys())[-6:]
            total_recent = sum(
                profile.activity_timeline[month]["total"] for month in recent_months
            )
            avg_monthly = total_recent / len(recent_months) if recent_months else 0

            report += f"""
ğŸ“ˆ ìµœê·¼ í™œë™ íŒ¨í„´ (ìµœê·¼ 6ê°œì›”)
- ì›”í‰ê·  í™œë™: {avg_monthly:.1f}ê±´
- í™œë™ ë¶„í¬: """

            for month in recent_months[-3:]:  # ìµœê·¼ 3ê°œì›”
                data = profile.activity_timeline[month]
                report += f"\n  {month}: ì´ {data['total']}ê±´ (ë²•ì•ˆ {data.get('bills', 0)}ê±´, ë°œì–¸ {data.get('speeches', 0)}ê±´)"

        # ì´ë…ì  íŠ¹ì§• í•´ì„
        report += f"\n\nğŸ§­ ì •ì¹˜ì  íŠ¹ì§• í•´ì„\n"

        ideology_score = profile.ideology_scores.overall_score
        if ideology_score < -0.3:
            report += (
                "- ì§„ë³´ì  ì„±í–¥ì„ ë³´ì´ëŠ” ì˜ì›ìœ¼ë¡œ, ì‚¬íšŒ ê°œí˜ê³¼ ë³µì§€ í™•ëŒ€ì— ê´€ì‹¬ì´ ë†’ìŒ\n"
            )
        elif ideology_score > 0.3:
            report += "- ë³´ìˆ˜ì  ì„±í–¥ì„ ë³´ì´ëŠ” ì˜ì›ìœ¼ë¡œ, ì‹œì¥ ê²½ì œì™€ ì „í†µ ê°€ì¹˜ ì¤‘ì‹œ\n"
        else:
            report += "- ì¤‘ë„ì  ì„±í–¥ì„ ë³´ì´ëŠ” ì˜ì›ìœ¼ë¡œ, ì‹¤ìš©ì ì´ê³  í•©ë¦¬ì ì¸ ì •ì±… ì¶”ì§„\n"

        # ì „ë¬¸ì„± íŠ¹ì§•
        if profile.specializations:
            main_area = profile.specializations[0].area.value
            report += f"- ì£¼ìš” ì „ë¬¸ ë¶„ì•¼ëŠ” '{main_area}'ë¡œ, í•´ë‹¹ ë¶„ì•¼ì—ì„œ ì§€ì†ì ì¸ í™œë™ì„ ë³´ì„\n"

        report += f"\n{'='*80}\n"

        return report

    @staticmethod
    def create_visualization_data(profile: PoliticalProfile) -> Dict:
        """ì‹œê°í™”ìš© ë°ì´í„° ìƒì„±"""
        # ì „ë¬¸ì„± ì°¨íŠ¸ ë°ì´í„°
        spec_data = {
            "areas": [spec.area.value for spec in profile.specializations[:5]],
            "scores": [spec.total_score for spec in profile.specializations[:5]],
        }

        # ê´€ì‹¬ì‚¬ ì›Œë“œí´ë¼ìš°ë“œ ë°ì´í„°
        interest_data = {word: score for word, score in profile.main_interests[:30]}

        # ì´ë… ì ìˆ˜ ë ˆì´ë” ì°¨íŠ¸ ë°ì´í„°
        ideology_data = {
            "bill_score": profile.ideology_scores.bill_score,
            "speech_score": profile.ideology_scores.keyword_score,
            "voting_score": profile.ideology_scores.voting_score,
            "overall_score": profile.ideology_scores.overall_score,
        }

        # ì‹œê°„ë³„ í™œë™ ì¶”ì´ ë°ì´í„°
        timeline_data = {
            "months": list(profile.activity_timeline.keys()),
            "activities": [
                data["total"] for data in profile.activity_timeline.values()
            ],
        }

        return {
            "specialization": spec_data,
            "interests": interest_data,
            "ideology": ideology_data,
            "timeline": timeline_data,
        }


# ì‚¬ìš© ì˜ˆì‹œ
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # API í‚¤ ì„¤ì •
    API_KEY = "YOUR_API_KEY_HERE"

    # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì´ì „ ì½”ë“œì˜ í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©)
    api_client = NationalAssemblyAPI(API_KEY)

    # í”„ë¡œíŒŒì¼ëŸ¬ ì´ˆê¸°í™”
    profiler = PoliticalProfiler(api_client)

    # ë¶„ì„í•  ì˜ì›
    member_name = "í™ê¸¸ë™"

    try:
        # ì¢…í•© í”„ë¡œí•„ ìƒì„±
        profile = profiler.create_comprehensive_profile(member_name)

        # ë³´ê³ ì„œ ìƒì„± ë° ì¶œë ¥
        report = ProfileReporter.generate_comprehensive_report(profile)
        print(report)

        # ì‹œê°í™” ë°ì´í„° ìƒì„±
        viz_data = ProfileReporter.create_visualization_data(profile)

        print("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        print(
            f"- ì£¼ìš” ì „ë¬¸ ë¶„ì•¼: {profile.specializations[0].area.value if profile.specializations else 'ì—†ìŒ'}"
        )
        print(f"- ì •ì¹˜ ì´ë…: {profile.ideology.value}")
        print(
            f"- í•µì‹¬ ê´€ì‹¬ì‚¬: {', '.join([word for word, _ in profile.main_interests[:3]])}"
        )
        print(
            f"- ìµœê·¼ 6ê°œì›” í™œë™ëŸ‰: {sum(data['total'] for data in list(profile.activity_timeline.values())[-6:])}ê±´"
        )

        # í”„ë¡œí•„ ë°ì´í„° ì €ì¥
        with open(f"{member_name}_political_profile.json", "w", encoding="utf-8") as f:
            # ë°ì´í„°í´ë˜ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            profile_dict = {
                "member_name": profile.member_name,
                "ideology": profile.ideology.value,
                "ideology_scores": profile.ideology_scores.__dict__,
                "specializations": [spec.__dict__ for spec in profile.specializations],
                "main_interests": profile.main_interests,
                "activity_timeline": profile.activity_timeline,
                "keyword_trends": profile.keyword_trends,
            }
            json.dump(profile_dict, f, ensure_ascii=False, indent=2)

        print(
            f"\nâœ… í”„ë¡œí•„ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ '{member_name}_political_profile.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        )

    except Exception as e:
        print(f"í”„ë¡œí•„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# ë¹„êµ ë¶„ì„ í•¨ìˆ˜
def compare_members(api_client, member_names: List[str]):
    """ì—¬ëŸ¬ ì˜ì› ë¹„êµ ë¶„ì„"""
    profiler = PoliticalProfiler(api_client)
    profiles = []

    for name in member_names:
        try:
            profile = profiler.create_comprehensive_profile(name)
            profiles.append(profile)
        except Exception as e:
            print(f"ì˜ì› '{name}' ë¶„ì„ ì‹¤íŒ¨: {e}")

    # ë¹„êµ ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"êµ­íšŒì˜ì› ë¹„êµ ë¶„ì„ ({len(profiles)}ëª…)")
    print(f"{'='*60}")

    print(f"{'ì˜ì›ëª…':<10} {'ì´ë…ì„±í–¥':<15} {'ì£¼ìš”ë¶„ì•¼':<15} {'ì´ë…ì ìˆ˜':<10}")
    print("-" * 60)

    for profile in profiles:
        main_area = (
            profile.specializations[0].area.value if profile.specializations else "ì—†ìŒ"
        )
        ideology_score = profile.ideology_scores.overall_score

        print(
            f"{profile.member_name:<10} {profile.ideology.value:<15} "
            f"{main_area:<15} {ideology_score:>+6.2f}"
        )


if __name__ == "__main__":
    main()
