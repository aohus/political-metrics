import asyncio
import glob
import json
import logging
import os
import re
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from datetime import datetime
from typing import List, Union

import aiofiles
import pandas as pd
from utils.file.fileio import read_file

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class BillInfo:
    """ë²•ì•ˆ ê¸°ë³¸ ì •ë³´ êµ¬ì¡°ì²´"""

    title: str
    bill_number: str
    proposal_date: str
    main_content: str
    reason: str


@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ êµ¬ì¡°ì²´"""

    bill_info: BillInfo
    policy_field: str
    sub_policy_fields: List[str]
    beneficiary_groups: List[str]
    economic_layers: List[str]
    political_spectrum: dict[str, float]
    policy_approach: str
    political_implications: List[str]
    ideology_score: float
    urgency_level: str
    social_impact: str


class PoliticalBillAnalyzer:
    def __init__(self, max_concurrent_tasks: int = 10):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        self.executor = ThreadPoolExecutor(max_workers=max_concurrent_tasks)
        self.keywords = self.load_keywords()

        self.policy_fields = self.keywords.policy_fields
        self.beneficiary_patterns = self.keywords.beneficiary_patterns
        self.political_spectrum_keywords = self.keywords.political_spectrum_keywords
        self.urgency_keywords = self.keywords.urgency_keywords
        self.social_impact_keywords = self.keywords.social_impact_keywords

    def load_keywords(self) -> dict[str, any]:
        from .keywords import KeywordDict
        return KeywordDict()

    def classify_policy_field(self, text: str, title_text: str, reason_text: str) -> tuple[str, List[str]]:
        """ì •ì±… ë¶„ì•¼ ë¶„ë¥˜ (ì£¼ ë¶„ì•¼ + ë¶€ë¶„ì•¼)"""
        field_scores = {}

        # ê°€ì¤‘ì¹˜ ì ìš© (ì œëª©ê³¼ ì´ìœ ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        title_weight = 3.0
        reason_weight = 2.0
        content_weight = 1.0

        for field, keywords in self.policy_fields.items():
            score = 0
            for keyword in keywords:
                # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
                score += len(re.findall(keyword, title_text, re.IGNORECASE)) * title_weight
                # ì´ìœ ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
                score += len(re.findall(keyword, reason_text, re.IGNORECASE)) * reason_weight
                # ì „ì²´ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
                score += len(re.findall(keyword, text, re.IGNORECASE)) * content_weight

            field_scores[field] = score

        # ì£¼ ë¶„ì•¼ ê²°ì •
        main_field = max(field_scores, key=field_scores.get) if field_scores else "ê¸°íƒ€"

        # ë¶€ë¶„ì•¼ ê²°ì • (ì ìˆ˜ê°€ ë†’ì€ ìƒìœ„ 3ê°œ)
        sorted_fields = sorted(field_scores.items(), key=lambda x: x[1], reverse=True)
        sub_fields = [field for field, score in sorted_fields[:3] if score > 0 and field != main_field]

        return main_field, sub_fields

    def analyze_beneficiaries(self, text: str) -> tuple[List[str], List[str]]:
        """ìˆ˜í˜œì¸µ ë¶„ì„ (ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜)"""
        beneficiary_groups = []
        economic_layers = []

        # ê°€ì¤‘ì¹˜ ì ìš© ë¶„ì„
        for group, patterns in self.beneficiary_patterns.items():
            group_score = 0
            for pattern in patterns:
                # ì •í™•í•œ ë§¤ì¹­ì— ë” ë†’ì€ ì ìˆ˜
                exact_matches = len(re.findall(f"\\b{pattern}\\b", text, re.IGNORECASE))
                partial_matches = len(re.findall(pattern, text, re.IGNORECASE)) - exact_matches

                group_score += exact_matches * 2 + partial_matches

            if group_score > 0:
                beneficiary_groups.append((group, group_score))

        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ ê²°ê³¼ë§Œ ì„ íƒ
        beneficiary_groups.sort(key=lambda x: x[1], reverse=True)
        beneficiary_groups = [group for group, score in beneficiary_groups[:10]]

        # ê²½ì œì  ê³„ì¸µ ë¶„ë¥˜ (ë” ì •í™•í•œ ë¶„ë¥˜)
        economic_mapping = {
            "ì„œë¯¼ì¸µ": ["ì €ì†Œë“ì¸µ", "ë†ë¯¼", "ì†Œìƒê³µì¸", "ìì˜ì—…", "ê·¼ë¡œì", "í”„ë¦¬ëœì„œ", "ë°°ë‹¬ê¸°ì‚¬", "íƒì‹œê¸°ì‚¬"],
            "ì¤‘ì‚°ì¸µ": ["ì¤‘ì‚°ì¸µ", "ì¼ë°˜ êµ­ë¯¼", "ê³µë¬´ì›", "ì „ë¬¸ì§", "ì§ì¥ì¸"],
            "ê³ ì†Œë“ì¸µ": ["ê³ ì†Œë“ì¸µ", "ìì‚°ê°€"],
            "ê¸°ì—…ì¸µ": ["ì¤‘ì†Œê¸°ì—…", "ì¤‘ê²¬ê¸°ì—…", "ëŒ€ê¸°ì—…", "ìŠ¤íƒ€íŠ¸ì—…", "í”Œë«í¼ê¸°ì—…", "ì œì¡°ì—…", "ì„œë¹„ìŠ¤ì—…"],
        }

        for layer, groups in economic_mapping.items():
            if any(group in beneficiary_groups for group in groups):
                economic_layers.append(layer)

        return beneficiary_groups, economic_layers

    def analyze_political_spectrum(self, text: str) -> dict[str, float]:
        """ì •ì¹˜ì  ì´ë… ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ (ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜)"""
        progressive_score = 0
        conservative_score = 0

        # ê°€ì¤‘ì¹˜ ì ìš© ë¶„ì„
        for category, keywords in self.political_spectrum_keywords["ì§„ë³´"].items():
            category_weight = 1.5 if category in ["ê²½ì œ", "ì‚¬íšŒ"] else 1.0
            for keyword in keywords:
                matches = len(re.findall(keyword, text, re.IGNORECASE))
                progressive_score += matches * category_weight

        for category, keywords in self.political_spectrum_keywords["ë³´ìˆ˜"].items():
            category_weight = 1.5 if category in ["ê²½ì œ", "ì•ˆë³´"] else 1.0
            for keyword in keywords:
                matches = len(re.findall(keyword, text, re.IGNORECASE))
                conservative_score += matches * category_weight

        total_score = progressive_score + conservative_score
        if total_score == 0:
            return {"ì§„ë³´": 0.5, "ë³´ìˆ˜": 0.5, "ì¤‘ë„": 1.0}

        prog_ratio = progressive_score / total_score
        cons_ratio = conservative_score / total_score

        # ì¤‘ë„ ì„±í–¥ ê³„ì‚° (ì–‘ê·¹í™” ì •ë„ì˜ ì—­ìˆ˜)
        polarization = abs(prog_ratio - cons_ratio)
        moderate_ratio = 1 - polarization

        return {"ì§„ë³´": prog_ratio, "ë³´ìˆ˜": cons_ratio, "ì¤‘ë„": moderate_ratio}

    def analyze_policy_approach(self, text: str) -> str:
        """ì •ì±… ë°©ì‹ ë¶„ì„ (ë” ì •í™•í•œ ë¶„ì„)"""
        approach_patterns = {
            "ìƒˆë¡œìš´ ì œë„ ì‹ ì„¤": ["ì‹ ì„¤", "ìƒˆë¡œ", "ìƒˆë¡­ê²Œ", "ë„ì…", "ì°½ì„¤", "ì œì •"],
            "ê¸°ì¡´ ì œë„ ì—°ì¥": ["ì—°ì¥", "ì¼ëª°", "ê¸°í•œ", "ì—°ê¸°", "ìœ ì˜ˆ", "ìœ ì§€"],
            "ê¸°ì¡´ ì œë„ í™•ëŒ€": ["í™•ëŒ€", "í™•ì¥", "ëŠ˜ë ¤", "ì¦ê°€", "ì¦ëŒ€", "ê°•í™”"],
            "ê¸°ì¡´ ì œë„ ê°œì •": ["ê°œì •", "ìˆ˜ì •", "ë³€ê²½", "ë³´ì™„", "ê°œì„ ", "ì •ë¹„"],
            "ê¸°ì¡´ ì œë„ íì§€": ["íì§€", "ì‚­ì œ", "ì—†ì• ", "ì² í", "ì¤‘ë‹¨", "ì¢…ë£Œ"],
            "ê¸°ì¡´ ì œë„ ì™„í™”": ["ì™„í™”", "ì™„ì¶©", "ê²½ê°", "ì¶•ì†Œ", "ê°ì¶•", "ê°ì†Œ"],
        }

        approach_scores = {}
        for approach, patterns in approach_patterns.items():
            score = 0
            for pattern in patterns:
                score += len(re.findall(pattern, text, re.IGNORECASE))
            approach_scores[approach] = score

        if approach_scores:
            return max(approach_scores, key=approach_scores.get)
        return "ê¸°íƒ€"

    def analyze_urgency_level(self, text: str) -> str:
        """ê¸´ê¸‰ì„± ìˆ˜ì¤€ ë¶„ì„"""
        urgency_scores = {}

        for level, keywords in self.urgency_keywords.items():
            score = 0
            for keyword in keywords:
                score += len(re.findall(keyword, text, re.IGNORECASE))
            urgency_scores[level] = score

        if urgency_scores:
            return max(urgency_scores, key=urgency_scores.get)
        return "ë³´í†µ"

    def analyze_social_impact(self, text: str) -> str:
        """ì‚¬íšŒì  ì˜í–¥ ë¶„ì„"""
        impact_scores = {}

        for impact, keywords in self.social_impact_keywords.items():
            score = 0
            for keyword in keywords:
                score += len(re.findall(keyword, text, re.IGNORECASE))
            impact_scores[impact] = score

        if impact_scores:
            return max(impact_scores, key=impact_scores.get)
        return "ë³´í†µ"

    def derive_political_implications(self, analysis_result: AnalysisResult) -> List[str]:
        """ì •ì¹˜ì  í•¨ì˜ ë„ì¶œ (í™•ì¥ëœ ë¶„ì„)"""
        implications = []

        # ì •ì±… ë¶„ì•¼ë³„ í•¨ì˜
        field_implications = {
            "ë””ì§€í„¸ì •ì±…": "ë””ì§€í„¸ ì „í™˜ê³¼ 4ì°¨ ì‚°ì—…í˜ëª… ëŒ€ì‘",
            "ì§€ì—­ê°œë°œ": "ì§€ì—­ ê· í˜•ë°œì „ê³¼ ë¶„ê¶Œí™” ì •ì±…",
            "ê²½ì œì •ì±…": "ê²½ì œì„±ì¥ê³¼ ì‚°ì—… ê²½ìŸë ¥ ê°•í™”",
            "ì‚¬íšŒì •ì±…": "ì‚¬íšŒì  í˜•í‰ì„±ê³¼ ë³µì§€ í™•ëŒ€",
            "ê¸°ìˆ í˜ì‹ ": "ë¯¸ë˜ ì„±ì¥ ë™ë ¥ê³¼ í˜ì‹  ìƒíƒœê³„ êµ¬ì¶•",
            "í™˜ê²½ì •ì±…": "ì§€ì†ê°€ëŠ¥í•œ ë°œì „ê³¼ ê¸°í›„ë³€í™” ëŒ€ì‘",
            "ì£¼íƒì •ì±…": "ì£¼ê±° ì•ˆì •ê³¼ ë¶€ë™ì‚° ì‹œì¥ ì¡°ì ˆ",
            "êµìœ¡ì •ì±…": "êµìœ¡ ê²©ì°¨ í•´ì†Œì™€ ì¸ì¬ ì–‘ì„±",
            "ë³´ê±´ì˜ë£Œ": "ì˜ë£Œ ì ‘ê·¼ì„±ê³¼ ê³µê³µë³´ê±´ ê°•í™”",
            "ë…¸ë™ì •ì±…": "ë…¸ë™ì ê¶Œìµ ë³´í˜¸ì™€ ê³ ìš© ì•ˆì •",
            "ê¸ˆìœµì •ì±…": "ê¸ˆìœµ ì•ˆì •ê³¼ ì„œë¯¼ ê¸ˆìœµ ì§€ì›",
            "ë¬¸í™”ì •ì±…": "ë¬¸í™” í–¥ìœ ê¶Œê³¼ ì°½ì¡°ê²½ì œ í™œì„±í™”",
            "êµ­ë°©ì •ì±…": "êµ­ê°€ ì•ˆë³´ì™€ ë°©ìœ„ë ¥ ê°•í™”",
            "ì™¸êµì •ì±…": "êµ­ì œ í˜‘ë ¥ê³¼ êµ­ìµ ì¦ì§„",
            "ë†ì—…ì •ì±…": "ë†ì—… ê²½ìŸë ¥ê³¼ ë†ì´Œ ë°œì „",
            "êµí†µì •ì±…": "êµí†µ ì¸í”„ë¼ì™€ ì´ë™ê¶Œ ë³´ì¥",
        }

        if analysis_result.policy_field in field_implications:
            implications.append(field_implications[analysis_result.policy_field])

        # ìˆ˜í˜œì¸µë³„ í•¨ì˜
        if "ì„œë¯¼ì¸µ" in analysis_result.economic_layers:
            implications.append("ì„œë¯¼ ìƒí™œ ì•ˆì •ê³¼ ì†Œë“ ì¬ë¶„ë°°")
        if "ê¸°ì—…ì¸µ" in analysis_result.economic_layers:
            implications.append("ê¸°ì—… í™œë™ ì§€ì›ê³¼ íˆ¬ì ì´‰ì§„")
        if "ì¤‘ì‚°ì¸µ" in analysis_result.economic_layers:
            implications.append("ì¤‘ì‚°ì¸µ ë³´í˜¸ì™€ ì•ˆì •ì  ì„±ì¥")
        if "ê³ ì†Œë“ì¸µ" in analysis_result.economic_layers:
            implications.append("ê³ ì†Œë“ì¸µ ëŒ€ìƒ ì •ì±… ì¡°ì •")

        # ì •ì¹˜ì  ìŠ¤í™íŠ¸ëŸ¼ë³„ í•¨ì˜
        if analysis_result.political_spectrum["ì§„ë³´"] > 0.6:
            implications.append("ì§„ë³´ì  ê°€ì¹˜ ì¶”êµ¬ì™€ ì‚¬íšŒ ê°œí˜")
        elif analysis_result.political_spectrum["ë³´ìˆ˜"] > 0.6:
            implications.append("ì•ˆì •ì„± ì¤‘ì‹œì™€ ê¸°ì¡´ ì§ˆì„œ ìœ ì§€")
        else:
            implications.append("ì‹¤ìš©ì  ì •ì±… ì ‘ê·¼ê³¼ ì¤‘ë„ ì§€í–¥")

        # ê¸´ê¸‰ì„±ë³„ í•¨ì˜
        if analysis_result.urgency_level == "ë§¤ìš° ê¸´ê¸‰":
            implications.append("ì¦‰ê°ì  ëŒ€ì‘ì´ í•„ìš”í•œ ì‚¬íšŒ í˜„ì•ˆ")
        elif analysis_result.urgency_level == "ê¸´ê¸‰":
            implications.append("ì‹ ì†í•œ ì •ì±… ëŒ€ì‘ í•„ìš”")
        elif analysis_result.urgency_level == "ì¥ê¸°":
            implications.append("ì¥ê¸°ì  ê´€ì ì˜ ì •ì±… ì¶”ì§„")

        # ì‚¬íšŒì  ì˜í–¥ë³„ í•¨ì˜
        if analysis_result.social_impact == "ê´‘ë²”ìœ„":
            implications.append("ì „ êµ­ë¯¼ ëŒ€ìƒì˜ í¬ê´„ì  ì •ì±…")
        elif analysis_result.social_impact == "ìƒë‹¹í•¨":
            implications.append("ì‚¬íšŒ ì „ë°˜ì— ìƒë‹¹í•œ ì˜í–¥")
        elif analysis_result.social_impact == "ì œí•œì ":
            implications.append("íŠ¹ì • ê³„ì¸µ ëŒ€ìƒì˜ ë§ì¶¤í˜• ì •ì±…")

        return implications

    async def get_bill_info(self, path) -> BillInfo:
        text = await read_file(path)
        reason = text.get("sections", {}).get("ì œì•ˆì´ìœ ", "ì´ìœ  ë¯¸í™•ì¸")
        if len(reason) < 10:
            reason = text.get("sections", {}).get("ì£¼ìš”ë‚´ìš©", "ì´ìœ  ë¯¸í™•ì¸")
        return BillInfo(
            title=text.get("title", "ì œëª© ë¯¸í™•ì¸"),
            bill_number=text.get("bill_number", "ë²ˆí˜¸ ë¯¸í™•ì¸"),
            proposal_date=text.get("proposal_date", "ë‚ ì§œ ë¯¸í™•ì¸"),
            main_content=text.get("full_text", "ë‚´ìš© ë¯¸í™•ì¸"),
            reason=reason,
        )

    async def analyze_single_bill(self, pdf_path: str) -> AnalysisResult:
        """ë‹¨ì¼ ë²•ì•ˆ ë¶„ì„ (ë¹„ë™ê¸°)"""
        async with self.semaphore:
            bill_info = await self.get_bill_info(pdf_path)
            if not bill_info:
                raise ValueError("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            text = bill_info.main_content

            # ê°ì¢… ë¶„ì„ ìˆ˜í–‰
            policy_field, sub_policy_fields = self.classify_policy_field(text, bill_info.title, bill_info.reason)
            beneficiary_groups, economic_layers = self.analyze_beneficiaries(text)
            political_spectrum = self.analyze_political_spectrum(text)
            policy_approach = self.analyze_policy_approach(text)
            urgency_level = self.analyze_urgency_level(text)
            social_impact = self.analyze_social_impact(text)

            # ì´ë… ì ìˆ˜ ê³„ì‚° (ì§„ë³´ -1, ë³´ìˆ˜ +1 ìŠ¤ì¼€ì¼)
            ideology_score = political_spectrum["ë³´ìˆ˜"] - political_spectrum["ì§„ë³´"]

            # ë¶„ì„ ê²°ê³¼ ìƒì„±
            analysis_result = AnalysisResult(
                bill_info=bill_info,
                policy_field=policy_field,
                sub_policy_fields=sub_policy_fields,
                beneficiary_groups=beneficiary_groups,
                economic_layers=economic_layers,
                political_spectrum=political_spectrum,
                policy_approach=policy_approach,
                political_implications=[],
                ideology_score=ideology_score,
                urgency_level=urgency_level,
                social_impact=social_impact,
            )

            # # ì •ì¹˜ì  í•¨ì˜ ë„ì¶œ
            analysis_result.political_implications = self.derive_political_implications(analysis_result)
            return analysis_result

    async def analyze_multiple_bills(self, pdf_paths: List[str], progress_callback=None) -> List[AnalysisResult]:
        """ì—¬ëŸ¬ ë²•ì•ˆ ì¼ê´„ ë¶„ì„ (ë¹„ë™ê¸°)"""
        results = []
        failed_files = []

        tasks = []
        for i, pdf_path in enumerate(pdf_paths):
            task = asyncio.create_task(self._analyze_with_progress(pdf_path, i, len(pdf_paths), progress_callback))
            tasks.append(task)

        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        completed_tasks = await asyncio.gather(*tasks, return_exceptions=True)

        for i, result in enumerate(completed_tasks):
            if isinstance(result, Exception):
                failed_files.append(pdf_paths[i])
                logger.error(f"ë²•ì•ˆ ë¶„ì„ ì‹¤íŒ¨ ({pdf_paths[i]}): {result}")
            else:
                results.append(result)

        if failed_files:
            logger.warning(f"ì´ {len(failed_files)}ê°œ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨")

        logger.info(f"ì „ì²´ ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì„±ê³µ, {len(failed_files)}ê°œ ì‹¤íŒ¨")
        return results

    async def _analyze_with_progress(self, pdf_path: str, index: int, total: int, progress_callback) -> AnalysisResult:
        """ì§„í–‰ë¥  ì½œë°±ê³¼ í•¨ê»˜ ë¶„ì„"""
        result = await self.analyze_single_bill(pdf_path)

        if progress_callback:
            progress_callback(index + 1, total, pdf_path)

        return result

    async def save_analysis_results(
        self, results: Union[AnalysisResult, List[AnalysisResult]], output_path: str, format_type: str = "json"
    ):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥ (ë¹„ë™ê¸°)"""
        if isinstance(results, AnalysisResult):
            results = [results]

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if format_type == "json":
            output_file = f"{output_path}_analysis_{timestamp}.json"
            await self._save_as_json(results, output_file)
        elif format_type == "excel":
            output_file = f"{output_path}_analysis_{timestamp}.xlsx"
            await self._save_as_excel(results, output_file)
        elif format_type == "text":
            output_file = f"{output_path}_analysis_{timestamp}.txt"
            await self._save_as_text(results, output_file)

        logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        return output_file

    async def _save_as_json(self, results: List[AnalysisResult], file_path: str):
        """JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë¹„ë™ê¸°)"""
        json_data = []
        for result in results:
            json_data.append(
                {
                    "bill_info": {
                        "title": result.bill_info.title,
                        "bill_number": result.bill_info.bill_number,
                        "proposal_date": result.bill_info.proposal_date,
                        "reason": result.bill_info.reason,
                    },
                    "analysis": {
                        "policy_field": result.policy_field,
                        "sub_policy_fields": result.sub_policy_fields,
                        "beneficiary_groups": result.beneficiary_groups,
                        "economic_layers": result.economic_layers,
                        "political_spectrum": result.political_spectrum,
                        "policy_approach": result.policy_approach,
                        "political_implications": result.political_implications,
                        "ideology_score": result.ideology_score,
                        "urgency_level": result.urgency_level,
                        "social_impact": result.social_impact,
                    },
                }
            )

        async with aiofiles.open(file_path, "w", encoding="utf-8") as f:
            await f.write(json.dumps(json_data, ensure_ascii=False, indent=2))

    async def _save_as_excel(self, results: List[AnalysisResult], file_path: str):
        """Excel í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë¹„ë™ê¸°)"""

        def _create_dataframe():
            data = []
            for result in results:
                data.append(
                    {
                        "ë²•ì•ˆëª…": result.bill_info.title,
                        "ì˜ì•ˆë²ˆí˜¸": result.bill_info.bill_number,
                        "ë°œì˜ì¼ì": result.bill_info.proposal_date,
                        "ì£¼ì •ì±…ë¶„ì•¼": result.policy_field,
                        "ë¶€ì •ì±…ë¶„ì•¼": ", ".join(result.sub_policy_fields),
                        "ìˆ˜í˜œì¸µ": ", ".join(result.beneficiary_groups),
                        "ê²½ì œê³„ì¸µ": ", ".join(result.economic_layers),
                        "ì •ì±…ë°©ì‹": result.policy_approach,
                        "ì§„ë³´ì„±í–¥": result.political_spectrum["ì§„ë³´"],
                        "ë³´ìˆ˜ì„±í–¥": result.political_spectrum["ë³´ìˆ˜"],
                        "ì¤‘ë„ì„±í–¥": result.political_spectrum["ì¤‘ë„"],
                        "ì´ë…ì ìˆ˜": result.ideology_score,
                        "ê¸´ê¸‰ì„±": result.urgency_level,
                        "ì‚¬íšŒì ì˜í–¥": result.social_impact,
                        "ì •ì¹˜ì í•¨ì˜": "; ".join(result.political_implications),
                    }
                )
            return pd.DataFrame(data)

        loop = asyncio.get_event_loop()
        df = await loop.run_in_executor(self.executor, _create_dataframe)
        await loop.run_in_executor(self.executor, df.to_excel, file_path, False)

    async def _save_as_text(self, results: List[AnalysisResult], file_path: str):
        """í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë¹„ë™ê¸°)"""
        content = []
        for i, result in enumerate(results, 1):
            content.append(f"=== ë²•ì•ˆ {i} ë¶„ì„ ê²°ê³¼ ===\n")
            content.append(f"ğŸ“‹ ë²•ì•ˆ ì •ë³´\n")
            content.append(f"- ì œëª©: {result.bill_info.title}\n")
            content.append(f"- ì˜ì•ˆë²ˆí˜¸: {result.bill_info.bill_number}\n")
            content.append(f"- ë°œì˜ì¼ì: {result.bill_info.proposal_date}\n\n")

            content.append(f"ğŸ¯ ë¶„ì„ ê²°ê³¼\n")
            content.append(f"- ì£¼ì •ì±…ë¶„ì•¼: {result.policy_field}\n")
            content.append(f"- ë¶€ì •ì±…ë¶„ì•¼: {', '.join(result.sub_policy_fields)}\n")
            content.append(f"- ìˆ˜í˜œì¸µ: {', '.join(result.beneficiary_groups)}\n")
            content.append(f"- ê²½ì œê³„ì¸µ: {', '.join(result.economic_layers)}\n")
            content.append(f"- ì •ì±…ë°©ì‹: {result.policy_approach}\n")
            content.append(f"- ì´ë…ì ìˆ˜: {result.ideology_score:.2f}\n")
            content.append(f"- ê¸´ê¸‰ì„±: {result.urgency_level}\n")
            content.append(f"- ì‚¬íšŒì ì˜í–¥: {result.social_impact}\n\n")

            content.append(f"ğŸ›ï¸ ì •ì¹˜ì  ìŠ¤í™íŠ¸ëŸ¼\n")
            for spectrum, score in result.political_spectrum.items():
                content.append(f"- {spectrum}: {score:.2f}\n")

            content.append(f"\nğŸ’¡ ì •ì¹˜ì  í•¨ì˜\n")
            for implication in result.political_implications:
                content.append(f"- {implication}\n")

            content.append(f"\n{'='*50}\n\n")

        async with aiofiles.open(file_path, "w", encoding="utf-8") as f:
            await f.write("".join(content))

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.executor.shutdown(wait=True)


# ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
def progress_callback(current, total, current_file):
    """ì§„í–‰ë¥  í‘œì‹œ ì½œë°±"""
    progress = (current / total) * 100
    print(f"\rì§„í–‰ë¥ : {progress:.1f}% ({current}/{total}) - {os.path.basename(current_file)}", end="", flush=True)
    if current == total:
        print()  # ì™„ë£Œ ì‹œ ìƒˆ ì¤„


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = PoliticalBillAnalyzer(max_concurrent_tasks=20)

    try:
        # ë‹¨ì¼ ë²•ì•ˆ ë¶„ì„ ì˜ˆì œ
        # print("=== ë‹¨ì¼ ë²•ì•ˆ ë¶„ì„ ===")
        # result = await analyzer.analyze_single_bill("example_bill.pdf")
        # await analyzer.save_analysis_results(result, "single_bill_analysis", "json")
        # print("ë‹¨ì¼ ë²•ì•ˆ ë¶„ì„ ì™„ë£Œ")

        # ì—¬ëŸ¬ ë²•ì•ˆ ì¼ê´„ ë¶„ì„ ì˜ˆì œ
        print("\n=== ì—¬ëŸ¬ ë²•ì•ˆ ì¼ê´„ ë¶„ì„ ===")
        filelist = glob.glob(f"{os.path.basename(os.path.__file__)}/*.txt")  # PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
        pdf_files = filelist[:10]  # ì˜ˆì‹œë¡œ 10ê°œ íŒŒì¼ë§Œ ë¶„ì„

        start_time = time.time()
        results = await analyzer.analyze_multiple_bills(pdf_files, progress_callback)
        end_time = time.time()

        await analyzer.save_analysis_results(results, "multiple_bills_analysis", "excel")
        print(f"ì´ {len(results)}ê°œ ë²•ì•ˆ ë¶„ì„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ)")

    except Exception as e:
        print(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
    finally:
        analyzer.close()


if __name__ == "__main__":
    asyncio.run(main())
